{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torchsummary\n",
    "\n",
    "from networks.generator import ResNetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple = transforms.Compose([\n",
    "    transforms.ToTensor(), # converts to [0,1] interval\n",
    "])\n",
    "mnist_trainset = datasets.MNIST(root='./datasets/mnist', train=True, download=True, transform=simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./datasets/mnist\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnistdenoizing_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):        \n",
    "        self.mnist_dataset = dataset\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.mnist_dataset[idx][0][0]\n",
    "        noise = np.random.random((28, 28)).astype(np.float32)\n",
    "        img_w_noise = img + torch.tensor(noise)\n",
    "        return torch.unsqueeze(img, 0).type(torch.double), torch.unsqueeze(img_w_noise, 0).type(torch.double)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_noise_dataset = Mnistdenoizing_dataset(mnist_trainset)\n",
    "train_set, val_set = torch.utils.data.random_split(mnist_noise_dataset, [1000, 59000])\n",
    "\n",
    "mnist_loader = DataLoader(mnist_trainset, batch_size=2,)\n",
    "mnist_noise_loader = DataLoader(mnist_noise_dataset, batch_size=3)\n",
    "for img, image_noise in mnist_noise_loader:\n",
    "    plt.imshow(image_noise[2][0])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]           3,136\n",
      "            Conv2d-2           [-1, 64, 28, 28]           3,136\n",
      "    InstanceNorm2d-3           [-1, 64, 28, 28]             128\n",
      "    InstanceNorm2d-4           [-1, 64, 28, 28]             128\n",
      "              ReLU-5           [-1, 64, 28, 28]               0\n",
      "              ReLU-6           [-1, 64, 28, 28]               0\n",
      "            Conv2d-7          [-1, 128, 14, 14]          73,728\n",
      "            Conv2d-8          [-1, 128, 14, 14]          73,728\n",
      "    InstanceNorm2d-9          [-1, 128, 14, 14]             256\n",
      "   InstanceNorm2d-10          [-1, 128, 14, 14]             256\n",
      "             ReLU-11          [-1, 128, 14, 14]               0\n",
      "             ReLU-12          [-1, 128, 14, 14]               0\n",
      "DownsamplingBlock-13          [-1, 128, 14, 14]               0\n",
      "DownsamplingBlock-14          [-1, 128, 14, 14]               0\n",
      "           Conv2d-15            [-1, 256, 7, 7]         294,912\n",
      "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
      "   InstanceNorm2d-17            [-1, 256, 7, 7]             512\n",
      "   InstanceNorm2d-18            [-1, 256, 7, 7]             512\n",
      "             ReLU-19            [-1, 256, 7, 7]               0\n",
      "             ReLU-20            [-1, 256, 7, 7]               0\n",
      "DownsamplingBlock-21            [-1, 256, 7, 7]               0\n",
      "DownsamplingBlock-22            [-1, 256, 7, 7]               0\n",
      "           Conv2d-23            [-1, 256, 7, 7]         589,824\n",
      "           Conv2d-24            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-25            [-1, 256, 7, 7]             512\n",
      "   InstanceNorm2d-26            [-1, 256, 7, 7]             512\n",
      "             ReLU-27            [-1, 256, 7, 7]               0\n",
      "             ReLU-28            [-1, 256, 7, 7]               0\n",
      "           Conv2d-29            [-1, 256, 7, 7]         589,824\n",
      "           Conv2d-30            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-31            [-1, 256, 7, 7]             512\n",
      "   InstanceNorm2d-32            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-33            [-1, 256, 7, 7]               0\n",
      "    ResidualBlock-34            [-1, 256, 7, 7]               0\n",
      "           Conv2d-35            [-1, 256, 7, 7]         589,824\n",
      "           Conv2d-36            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-37            [-1, 256, 7, 7]             512\n",
      "   InstanceNorm2d-38            [-1, 256, 7, 7]             512\n",
      "             ReLU-39            [-1, 256, 7, 7]               0\n",
      "             ReLU-40            [-1, 256, 7, 7]               0\n",
      "           Conv2d-41            [-1, 256, 7, 7]         589,824\n",
      "           Conv2d-42            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-43            [-1, 256, 7, 7]             512\n",
      "   InstanceNorm2d-44            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-45            [-1, 256, 7, 7]               0\n",
      "    ResidualBlock-46            [-1, 256, 7, 7]               0\n",
      "ResNetGenerator_encoder-47            [-1, 256, 7, 7]               0\n",
      "ResNetGenerator_encoder-48            [-1, 256, 7, 7]               0\n",
      "  ConvTranspose2d-49          [-1, 128, 14, 14]         294,912\n",
      "  ConvTranspose2d-50          [-1, 128, 14, 14]         294,912\n",
      "   InstanceNorm2d-51          [-1, 128, 14, 14]             256\n",
      "   InstanceNorm2d-52          [-1, 128, 14, 14]             256\n",
      "             ReLU-53          [-1, 128, 14, 14]               0\n",
      "             ReLU-54          [-1, 128, 14, 14]               0\n",
      "  UpsamplingBlock-55          [-1, 128, 14, 14]               0\n",
      "  UpsamplingBlock-56          [-1, 128, 14, 14]               0\n",
      "  ConvTranspose2d-57           [-1, 64, 28, 28]          73,728\n",
      "  ConvTranspose2d-58           [-1, 64, 28, 28]          73,728\n",
      "   InstanceNorm2d-59           [-1, 64, 28, 28]             128\n",
      "   InstanceNorm2d-60           [-1, 64, 28, 28]             128\n",
      "             ReLU-61           [-1, 64, 28, 28]               0\n",
      "             ReLU-62           [-1, 64, 28, 28]               0\n",
      "  UpsamplingBlock-63           [-1, 64, 28, 28]               0\n",
      "  UpsamplingBlock-64           [-1, 64, 28, 28]               0\n",
      "           Conv2d-65            [-1, 1, 28, 28]           3,136\n",
      "           Conv2d-66            [-1, 1, 28, 28]           3,136\n",
      "             Tanh-67            [-1, 1, 28, 28]               0\n",
      "             Tanh-68            [-1, 1, 28, 28]               0\n",
      "ResNetGenerator_decoder-69            [-1, 1, 28, 28]               0\n",
      "ResNetGenerator_decoder-70            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 6,212,352\n",
      "Trainable params: 6,212,352\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 11.71\n",
      "Params size (MB): 23.70\n",
      "Estimated Total Size (MB): 35.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNetGenerator(c_dim=1, kernel_size=3, repeat_num=2)\n",
    "# nn.init.xavier_normal(model.parameters())\n",
    "# resnet = torchvision.models.resnet18()\n",
    "torchsummary.summary(model, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "criterian = nn.MSELoss()\n",
    "def train(model, dataset, num_epoch=32, gd=None):\n",
    "    model.double()\n",
    "    if gd is None:\n",
    "        gd = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    dataloader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    losses = []\n",
    "#     dataloader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#     scores = []\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        model.train(True)\n",
    "        for i, batch in enumerate(dataloader):\n",
    "#             print(i)\n",
    "            gd.zero_grad()\n",
    "#             img = torch.tensor(batch[0], dtype=torch.double, requires_grad=True)\n",
    "#             img_noise = torch.tensor(batch[1], dtype=torch.double, requires_grad=True)\n",
    "            batch[0].requires_grad = True\n",
    "            \n",
    "            batch[1].requires_grad = True\n",
    "            f = model(batch[0])\n",
    "#             print(img_noise.shape)\n",
    "            loss = criterian(batch[1], f)\n",
    "#             return batch\n",
    "            loss.backward()\n",
    "            losses.append(loss.data.cpu().numpy())\n",
    "            gd.step()\n",
    "            gd.zero_grad()\n",
    "#             if i == 2000:\n",
    "#                 break\n",
    "        train_mse = np.mean(losses[-(i+1):])\n",
    "        \n",
    "        model.train(False)\n",
    "#         for i, (batch) in enumerate(dataloader_test):\n",
    "#             batch = batch.to(device=device)\n",
    "#             scores.append(model.batch_loss(batch, batch).data.cpu().numpy())\n",
    "#         test_mse  = np.mean(scores[-(i+1):])\n",
    "\n",
    "        print(f\"{epoch+1}, Train loss: {train_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, Train loss: 0.317239230005616\n",
      "2, Train loss: 0.3142157691322865\n",
      "3, Train loss: 0.3143621743294133\n",
      "4, Train loss: 0.3144141610665518\n",
      "5, Train loss: 0.31401600645856326\n",
      "6, Train loss: 0.31429604528064387\n",
      "7, Train loss: 0.3146241350483867\n",
      "8, Train loss: 0.31520657837911026\n",
      "9, Train loss: 0.3142684421650919\n",
      "10, Train loss: 0.3150487802269205\n",
      "11, Train loss: 0.3143673048346844\n",
      "12, Train loss: 0.31464067886363173\n",
      "13, Train loss: 0.31429330177293535\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-5d2d77ce20c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist_noise_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-58-edfa16c819ae>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, num_epoch, gd)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#             return batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/ML_practice/data-venv/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Program/ML_practice/data-venv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, mnist_noise_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.tensor(mnist_noise_dataset[0][0], dtype=torch.float, requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkBase(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetworkBase, self).__init__()\n",
    "        self._name = 'BaseNetwork'\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.apply(self._weights_init_fn)\n",
    "\n",
    "    def _weights_init_fn(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "            if hasattr(m.bias, 'data'):\n",
    "                m.bias.data.fill_(0)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "    def _get_norm_layer(self, norm_type='batch'):\n",
    "        if norm_type == 'batch':\n",
    "            norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n",
    "        elif norm_type == 'instance':\n",
    "            norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)\n",
    "        elif norm_type == 'batchnorm2d':\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        else:\n",
    "            raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "\n",
    "        return norm_layer\n",
    "\n",
    "    def forward(self, *input):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual Block.\"\"\"\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(dim_out, dim_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.InstanceNorm2d(dim_out, affine=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.main(x)\n",
    "\n",
    "\n",
    "class ResNetGenerator1(nn.Module):\n",
    "    \"\"\"Generator. Encoder-Decoder Architecture.\"\"\"\n",
    "    def __init__(self, conv_dim=64, c_dim=5, repeat_num=9, k_size=4, n_down=2):\n",
    "        super(ResNetGenerator1, self).__init__()\n",
    "        self._name = 'resnet_generator'\n",
    "\n",
    "        layers = []\n",
    "        layers.append(nn.Conv2d(c_dim, conv_dim, kernel_size=7, stride=1, padding=3, bias=False))\n",
    "        layers.append(nn.InstanceNorm2d(conv_dim, affine=True))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        # Down-Sampling\n",
    "        curr_dim = conv_dim\n",
    "        for i in range(n_down):\n",
    "            layers.append(nn.Conv2d(curr_dim, curr_dim*2, kernel_size=k_size, stride=2, padding=1, bias=False))\n",
    "            layers.append(nn.InstanceNorm2d(curr_dim*2, affine=True))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            curr_dim = curr_dim * 2\n",
    "\n",
    "        # Bottleneck\n",
    "        for i in range(repeat_num):\n",
    "            layers.append(ResidualBlock(dim_in=curr_dim, dim_out=curr_dim))\n",
    "\n",
    "        # Up-Sampling\n",
    "        for i in range(n_down):\n",
    "            layers.append(nn.ConvTranspose2d(curr_dim, curr_dim//2, kernel_size=k_size, stride=2, padding=1,\n",
    "                                             output_padding=1, bias=False))\n",
    "            layers.append(nn.InstanceNorm2d(curr_dim//2, affine=True))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "            curr_dim = curr_dim // 2\n",
    "\n",
    "        layers.append(nn.Conv2d(curr_dim, 1, kernel_size=7, stride=1, padding=3, bias=False))\n",
    "        layers.append(nn.Tanh())\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, c=None):\n",
    "        if c is not None:\n",
    "            # replicate spatially and concatenate domain information\n",
    "            c = c.unsqueeze(2).unsqueeze(3)\n",
    "            c = c.expand(c.size(0), c.size(1), x.size(2), x.size(3))\n",
    "            x = torch.cat([x, c], dim=1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 28, 28]          15,680\n",
      "    InstanceNorm2d-2           [-1, 64, 28, 28]             128\n",
      "              ReLU-3           [-1, 64, 28, 28]               0\n",
      "            Conv2d-4          [-1, 128, 14, 14]         131,072\n",
      "    InstanceNorm2d-5          [-1, 128, 14, 14]             256\n",
      "              ReLU-6          [-1, 128, 14, 14]               0\n",
      "            Conv2d-7            [-1, 256, 7, 7]         524,288\n",
      "    InstanceNorm2d-8            [-1, 256, 7, 7]             512\n",
      "              ReLU-9            [-1, 256, 7, 7]               0\n",
      "           Conv2d-10            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-11            [-1, 256, 7, 7]             512\n",
      "             ReLU-12            [-1, 256, 7, 7]               0\n",
      "           Conv2d-13            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-14            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-15            [-1, 256, 7, 7]               0\n",
      "           Conv2d-16            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-17            [-1, 256, 7, 7]             512\n",
      "             ReLU-18            [-1, 256, 7, 7]               0\n",
      "           Conv2d-19            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-20            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-21            [-1, 256, 7, 7]               0\n",
      "           Conv2d-22            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-23            [-1, 256, 7, 7]             512\n",
      "             ReLU-24            [-1, 256, 7, 7]               0\n",
      "           Conv2d-25            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-26            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-27            [-1, 256, 7, 7]               0\n",
      "           Conv2d-28            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-29            [-1, 256, 7, 7]             512\n",
      "             ReLU-30            [-1, 256, 7, 7]               0\n",
      "           Conv2d-31            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-32            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-33            [-1, 256, 7, 7]               0\n",
      "           Conv2d-34            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-35            [-1, 256, 7, 7]             512\n",
      "             ReLU-36            [-1, 256, 7, 7]               0\n",
      "           Conv2d-37            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-38            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-39            [-1, 256, 7, 7]               0\n",
      "           Conv2d-40            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-41            [-1, 256, 7, 7]             512\n",
      "             ReLU-42            [-1, 256, 7, 7]               0\n",
      "           Conv2d-43            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-44            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-45            [-1, 256, 7, 7]               0\n",
      "           Conv2d-46            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-47            [-1, 256, 7, 7]             512\n",
      "             ReLU-48            [-1, 256, 7, 7]               0\n",
      "           Conv2d-49            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-50            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-51            [-1, 256, 7, 7]               0\n",
      "           Conv2d-52            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-53            [-1, 256, 7, 7]             512\n",
      "             ReLU-54            [-1, 256, 7, 7]               0\n",
      "           Conv2d-55            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-56            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-57            [-1, 256, 7, 7]               0\n",
      "           Conv2d-58            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-59            [-1, 256, 7, 7]             512\n",
      "             ReLU-60            [-1, 256, 7, 7]               0\n",
      "           Conv2d-61            [-1, 256, 7, 7]         589,824\n",
      "   InstanceNorm2d-62            [-1, 256, 7, 7]             512\n",
      "    ResidualBlock-63            [-1, 256, 7, 7]               0\n",
      "  ConvTranspose2d-64          [-1, 128, 15, 15]         524,288\n",
      "   InstanceNorm2d-65          [-1, 128, 15, 15]             256\n",
      "             ReLU-66          [-1, 128, 15, 15]               0\n",
      "  ConvTranspose2d-67           [-1, 64, 31, 31]         131,072\n",
      "   InstanceNorm2d-68           [-1, 64, 31, 31]             128\n",
      "             ReLU-69           [-1, 64, 31, 31]               0\n",
      "           Conv2d-70            [-1, 5, 31, 31]          15,680\n",
      "             Tanh-71            [-1, 5, 31, 31]               0\n",
      "================================================================\n",
      "Total params: 11,969,408\n",
      "Trainable params: 11,969,408\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 9.32\n",
      "Params size (MB): 45.66\n",
      "Estimated Total Size (MB): 54.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "m = ResNetGenerator1()\n",
    "torchsummary.summary(m, (5, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-venv",
   "language": "python",
   "name": "data-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
